{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.5.2 (SDL 2.28.3, Python 3.10.11)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from stable_baselines3.common.results_plotter import load_results, ts2xy\n",
    "from stable_baselines3.common import results_plotter\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "\n",
    "import sys\n",
    "# direc = os.path.dirname(__file__)\n",
    "# pri&\n",
    "# caution: path[0] is reserved for script path (or '' in REPL)\n",
    "# print(str(path)+'/ppo')\n",
    "sys.path.insert(1, '/Users/faridounet/PhD/TransportersDilemma')\n",
    "from a_star import A_Star\n",
    "from SA_baseline import recuit\n",
    "from greedy_baseline import baseline\n",
    "from assignment import RemoveActionEnv, AssignmentEnv, GameEnv\n",
    "import pickle\n",
    "from shortcut import multi_types\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import collections\n",
    "\n",
    "from shortcut import multi_types\n",
    "from GameLearning import LRI, GameLearning, EXP3\n",
    "from SA_baseline import recuit\n",
    "from a_star import A_Star\n",
    "from greedy_baseline import baseline, greedy\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DP(env : RemoveActionEnv, excess, log = False):\n",
    "    \n",
    "    rtes = np.array([\n",
    "        [\n",
    "            env._env.initial_routes[m, i] \n",
    "            for i in range(0, len(env._env.initial_routes[m]), 2)\n",
    "        ]\n",
    "        for m in range(len(env._env.initial_routes))\n",
    "    ], dtype=int)\n",
    "\n",
    "\n",
    "    # print(env._env.distance_matrix)\n",
    "    # print(CM)\n",
    "    coeff = env._env._game.emissions_KM\n",
    "    # CM = np.array([\n",
    "    #     env._env.distance_matrix*coeff[i]\n",
    "    #     for i in range(len(coeff))\n",
    "    # ]).copy()\n",
    "    a = multi_types(env._env.distance_matrix, rtes, coeff, excess)\n",
    "\n",
    "\n",
    "    _, r, *_, info = env.step(a)\n",
    "    \n",
    "    if log:\n",
    "        print(env.destinations)\n",
    "        print(env._env.distance_matrix)\n",
    "    info['rtes'] = rtes\n",
    "    return a, r, info\n",
    "\n",
    "def SA(env, log = False):\n",
    "    \n",
    "    if log:\n",
    "        print(env.destinations)\n",
    "        print(env._env.distance_matrix)\n",
    "    T_init = 5_000\n",
    "    T_limit = 1\n",
    "    lamb = 0.9999\n",
    "    T = 100_000\n",
    "\n",
    "    action_SA, *_ = recuit(deepcopy(env._env), T_init, T_limit, lamb, H=T)\n",
    "            # res = recuit_multiple(game, T_init = T_init, T_limit = T_limit, lamb = lamb, log=log, H=T)\n",
    "    a = np.where(action_SA == 0)[0]\n",
    "\n",
    "    # CM = np.array([\n",
    "    #     env._env.distance_matrix*coeff[i]\n",
    "    #     for i in range(len(coeff))\n",
    "    # ]).copy()\n",
    "\n",
    "    # env = RemoveActionEnv(game = g, saved_routes = routes, saved_dests=dests, \n",
    "    #                       obs_mode='elimination_gain', \n",
    "    #                       action_mode = 'destinations',\n",
    "    #                         change_instance = True, rewards_mode='normalized_terminal', instance_id = 89)\n",
    "\n",
    "    _, r, *_, info = env.step(a)\n",
    "    info['initial routes'] = env._env.initial_routes\n",
    "    if log:\n",
    "        print(env.destinations)\n",
    "        print(env._env.distance_matrix)\n",
    "    \n",
    "    return a, r, info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 50\n",
    "with open(f'RL/game_K{K}.pkl', 'rb') as f:\n",
    "    g = pickle.load(f)\n",
    "routes = np.load(f'RL/routes_K{K}.npy')\n",
    "dests = np.load(f'RL/destinations_K{K}.npy')\n",
    "\n",
    "with open(f'res_compare_EG_A*_SA_K{K}_n100.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "    \n",
    "if K == 100:\n",
    "    g.Q = 40\n",
    "    \n",
    "if K == 15:\n",
    "    g.Q = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "res_A\n",
      "23\n",
      "[ 4 14 17 24 30 32 38 40 43 47]\n",
      "res_A\n",
      "48\n",
      "[ 2  3  4  7 10 19 22 24 35 39 41 43 44]\n",
      "res_A\n",
      "72\n",
      "[ 0  1  2  3  7  8 10 13 15 16 22 23 26 28 32 35 39 40 41 47]\n"
     ]
    }
   ],
   "source": [
    "# On recalcule les rewards\n",
    "rewards = []\n",
    "for k in data.keys():\n",
    "    rs = np.zeros(len(data[k]))\n",
    "    for i in data[k].keys():\n",
    "        sol = data[k][i]['sol']\n",
    "        env = RemoveActionEnv(game = g, saved_routes = routes, saved_dests=dests, \n",
    "                      obs_mode='elimination_gain', \n",
    "                      action_mode = 'destinations',\n",
    "                        change_instance = True, rewards_mode='normalized_terminal', instance_id = int(i))\n",
    "        env.reset()\n",
    "        _, r, *_ = env.step(sol)\n",
    "        if r == 0:\n",
    "            print(k)\n",
    "            print(i)\n",
    "            print(sol)\n",
    "        rs[i] = r\n",
    "    rewards.append(rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# affichage\n",
    "rr = []\n",
    "for rs in rewards:\n",
    "    rr.append(rs/(rewards[0]))\n",
    "    \n",
    "plt.boxplot(\n",
    "        rr,\n",
    "        patch_artist=True,\n",
    "        )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([14, 57, 90]),)\n",
      "(array([], dtype=int64),)\n",
      "(array([], dtype=int64),)\n"
     ]
    }
   ],
   "source": [
    "# On regarde ou la DP sous-performe\n",
    "print(np.where(rr[1]>1))\n",
    "print(np.where(rr[2]>1))\n",
    "print(np.where(rr[3]>1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On cible une instance\n",
    "instance = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "instance info :\n",
      "{'solution_found': False, 'costs': 155.0, 'time_per_vehicle': array([0., 0., 0., 0.]), 'distance_per_vehicle': array([30., 65., 10., 50.]), 'excess_emission': -0.5, 'omitted': array([10, 23, 40, 43, 44, 45, 46, 47, 48, 49, 50])}\n",
      "la solution calculee à nouveau :  [10 47 48 45 49 50 46 44 43 40 23]\n",
      "reward obtenue par la solution calculee à nouveau :  0.7386666666666667\n",
      "la solution calculee dans la sim :  [10 47 48 45 49 50 46 44 43 40 23]\n",
      "reward obtenue par la solution calculee dans la sim :  0.7386666666666667\n"
     ]
    }
   ],
   "source": [
    "# On reessaye la DP\n",
    "env = RemoveActionEnv(game = g, saved_routes = routes, saved_dests=dests, \n",
    "                      obs_mode='elimination_gain', \n",
    "                      action_mode = 'destinations',\n",
    "                        change_instance = False, rewards_mode='normalized_terminal', instance_id = instance)\n",
    "_, info = env.reset()\n",
    "excess = info['excess_emission']\n",
    "\n",
    "rtes = np.array([\n",
    "    [\n",
    "        env._env.initial_routes[m, i] \n",
    "        for i in range(0, len(env._env.initial_routes[m]), 2)\n",
    "    ]\n",
    "    for m in range(len(env._env.initial_routes))\n",
    "], dtype=int)\n",
    "\n",
    "\n",
    "# print(env._env.distance_matrix)\n",
    "# print(CM)\n",
    "coeff = env._env._game.emissions_KM\n",
    "# CM = np.array([\n",
    "#     env._env.distance_matrix*coeff[i]\n",
    "#     for i in range(len(coeff))\n",
    "# ]).copy()\n",
    "a = multi_types(env._env.distance_matrix, rtes, coeff, excess)\n",
    "\n",
    "\n",
    "_, r, *_, info = env.step(a)\n",
    "\n",
    "print('instance info :')\n",
    "print(info)\n",
    "\n",
    "print('la solution calculee à nouveau : ', a +1)\n",
    "print('reward obtenue par la solution calculee à nouveau : ', r)\n",
    "\n",
    "print('la solution calculee dans la sim : ', data['res_DP'][instance]['sol'] + 1)\n",
    "print('reward obtenue par la solution calculee dans la sim : ', rewards[0][instance])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0 34 35 36 37 30 28 27 26 25 29  0  0  0  0  0  0]\n",
      " [ 0 33 20 21 22 14 10  9  5  4  3  2 13  8 19 18  0]\n",
      " [ 0 42 41 47 48 45 49 50 46 44 43 39  0  0  0  0  0]\n",
      " [ 0 38 32 40 31 23 15 11  1  7  6 12 16 17 24  0  0]]\n"
     ]
    }
   ],
   "source": [
    "print(rtes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "la solution calculee à nouveau :  [40 41 43 44 45 46 47 48 49 50]\n",
      "reward obtenue par la solution calculee à nouveau :  0.7573333333333333\n",
      "la solution calculee dans la sim :  [23 40 43 44 45 46 47 48 49 50]\n",
      "reward obtenue par la solution calculee dans la sim :  0.7573333333333333\n"
     ]
    }
   ],
   "source": [
    "env = RemoveActionEnv(game = g, saved_routes = routes, saved_dests=dests, \n",
    "                    obs_mode='elimination_gain', \n",
    "                    action_mode = 'destinations',\n",
    "                    change_instance = False, rewards_mode='normalized_terminal', instance_id = instance\n",
    ")\n",
    "_, info = env.reset()\n",
    "excess = info['excess_emission']\n",
    "T_init = 5_000\n",
    "T_limit = 1\n",
    "lamb = 0.9999\n",
    "T = 100_000\n",
    "\n",
    "action_SA, *_ = recuit(deepcopy(env._env), T_init, T_limit, lamb, H=T)\n",
    "        # res = recuit_multiple(game, T_init = T_init, T_limit = T_limit, lamb = lamb, log=log, H=T)\n",
    "a = np.where(action_SA == 0)[0]\n",
    "\n",
    "# CM = np.array([\n",
    "#     env._env.distance_matrix*coeff[i]\n",
    "#     for i in range(len(coeff))\n",
    "# ]).copy()\n",
    "\n",
    "# env = RemoveActionEnv(game = g, saved_routes = routes, saved_dests=dests, \n",
    "#                       obs_mode='elimination_gain', \n",
    "#                       action_mode = 'destinations',\n",
    "#                         change_instance = True, rewards_mode='normalized_terminal', instance_id = 89)\n",
    "\n",
    "env.reset()\n",
    "_, r, *_, info = env.step(a)\n",
    "print('la solution calculee à nouveau : ', a + 1)\n",
    "print('reward obtenue par la solution calculee à nouveau : ', r)\n",
    "\n",
    "print('la solution calculee dans la sim : ', data['res_SA'][instance]['sol'] +1)\n",
    "print('reward obtenue par la solution calculee dans la sim : ', rewards[1][instance])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.        , 0.75      , 0.        , 0.25016661, 0.25      ,\n",
       "        0.75049983, 0.50033322, 0.33355548, 0.5       , 0.25      ]),\n",
       " {'solution_found': True,\n",
       "  'costs': 63.0,\n",
       "  'time_per_vehicle': <function time.time>,\n",
       "  'distance_per_vehicle': array([33., 30.]),\n",
       "  'excess_emission': 7.300000000000001,\n",
       "  'omitted': array([], dtype=int64)})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from assignment import AssignmentGame\n",
    "\n",
    "K = 10\n",
    "with open(f'RL/game_K{K}.pkl', 'rb') as f:\n",
    "    g = pickle.load(f)\n",
    "routes = np.load(f'RL/routes_K{K}.npy')\n",
    "dests = np.load(f'RL/destinations_K{K}.npy')\n",
    "\n",
    "\n",
    "# g = AssignmentGame(\n",
    "#             grid_size=12,\n",
    "#             max_capacity=1,\n",
    "#             Q = 7,\n",
    "#             K=2,\n",
    "#             emissions_KM = [.1, .3],\n",
    "#             costs_KM = [1, 1],\n",
    "#             seed=42\n",
    "#         )\n",
    "\n",
    "env = RemoveActionEnv(game = g, saved_routes = routes, saved_dests=dests, \n",
    "                      obs_mode='elimination_gain', \n",
    "                      action_mode = 'destinations',\n",
    "                        change_instance = True, rewards_mode='normalized_terminal', instance_id = 0)\n",
    "# env = RemoveActionEnv(game = g)\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.        , 0.75      , 0.        , 0.25016661, 0.25      ,\n",
       "        0.75049983, 0.50033322, 0.33355548, 0.5       , 0.25      ]),\n",
       " 0.0,\n",
       " False,\n",
       " False,\n",
       " {'solution_found': False,\n",
       "  'costs': 63.0,\n",
       "  'time_per_vehicle': array([0., 0.]),\n",
       "  'distance_per_vehicle': array([33., 30.]),\n",
       "  'excess_emission': 7.300000000000001,\n",
       "  'omitted': array([], dtype=int64)})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.step([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "21\n",
      "instance info :\n",
      "{'solution_found': True, 'costs': 51.0, 'time_per_vehicle': <built-in function time>, 'distance_per_vehicle': array([35., 16.]), 'excess_emission': 3.3000000000000007, 'omitted': array([], dtype=int64)}\n",
      "routes : \n",
      " [[ 0  3  4  9  5 10  0]\n",
      " [ 0  8  1  2  6  7  0]]\n",
      "----------\n",
      "la solution DP :  [3 8 6 7]\n",
      "reward DP :  0.5\n",
      "info DP :  {'solution_found': False, 'costs': 31.0, 'time_per_vehicle': array([0., 0.]), 'distance_per_vehicle': array([26.,  5.]), 'excess_emission': -0.9000000000000004, 'omitted': array([3, 6, 7, 8]), 'rtes': array([[ 0,  3,  4,  9,  5, 10,  0],\n",
      "       [ 0,  8,  1,  2,  6,  7,  0]])}\n",
      "la solution SA :  [3 6 7]\n",
      "reward SA :  0.5903225806451613\n",
      "info DP :  {'solution_found': False, 'costs': 34.0, 'time_per_vehicle': array([0., 0.]), 'distance_per_vehicle': array([26.,  8.]), 'excess_emission': 0.0, 'omitted': array([3, 6, 7]), 'initial routes': array([[0.0000e+00, 9.0090e+03, 3.0000e+00, 6.0060e+03, 4.0000e+00,\n",
      "        2.0020e+03, 9.0000e+00, 5.0050e+03, 5.0000e+00, 2.0020e+03,\n",
      "        1.0000e+01, 1.1011e+04, 0.0000e+00],\n",
      "       [0.0000e+00, 9.0030e+03, 8.0000e+00, 6.0020e+03, 1.0000e+00,\n",
      "        6.0020e+03, 2.0000e+00, 6.0020e+03, 6.0000e+00, 9.0030e+03,\n",
      "        7.0000e+00, 1.2004e+04, 0.0000e+00]])}\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "22\n",
      "instance info :\n",
      "{'solution_found': True, 'costs': 60.0, 'time_per_vehicle': <built-in function time>, 'distance_per_vehicle': array([38., 22.]), 'excess_emission': 5.4, 'omitted': array([], dtype=int64)}\n",
      "routes : \n",
      " [[ 0 10  9  4  1  7  0]\n",
      " [ 0  8  3  5  2  6  0]]\n",
      "----------\n",
      "la solution DP :  [10  8  3  5  2]\n",
      "reward DP :  0.3967741935483871\n",
      "info DP :  {'solution_found': False, 'costs': 32.0, 'time_per_vehicle': array([0., 0.]), 'distance_per_vehicle': array([28.,  4.]), 'excess_emission': -1.0, 'omitted': array([ 2,  3,  5,  8, 10]), 'rtes': array([[ 0, 10,  9,  4,  1,  7,  0],\n",
      "       [ 0,  8,  3,  5,  2,  6,  0]])}\n",
      "la solution SA :  [2 3 5 8]\n",
      "reward SA :  0.4645161290322581\n",
      "info DP :  {'solution_found': False, 'costs': 42.0, 'time_per_vehicle': array([0., 0.]), 'distance_per_vehicle': array([38.,  4.]), 'excess_emission': 0.0, 'omitted': array([2, 3, 5, 8]), 'initial routes': array([[0.0000e+00, 1.3013e+04, 1.0000e+01, 8.0080e+03, 9.0000e+00,\n",
      "        2.0020e+03, 4.0000e+00, 5.0050e+03, 1.0000e+00, 3.0030e+03,\n",
      "        7.0000e+00, 7.0070e+03, 0.0000e+00],\n",
      "       [0.0000e+00, 3.0010e+04, 8.0000e+00, 6.0020e+03, 3.0000e+00,\n",
      "        3.0010e+03, 5.0000e+00, 1.2004e+04, 2.0000e+00, 9.0030e+03,\n",
      "        6.0000e+00, 6.0020e+03, 0.0000e+00]])}\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;241m*\u001b[39m_, info \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mreset()\n\u001b[1;32m      8\u001b[0m aDP, rDP, infoDP \u001b[38;5;241m=\u001b[39m DP(deepcopy(env), info[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexcess_emission\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m----> 9\u001b[0m aSA, rSA, infoSA \u001b[38;5;241m=\u001b[39m \u001b[43mSA\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m rSA\u001b[38;5;241m>\u001b[39mrDP:\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;241m50\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m+\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[9], line 40\u001b[0m, in \u001b[0;36mSA\u001b[0;34m(env, log)\u001b[0m\n\u001b[1;32m     37\u001b[0m lamb \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.9999\u001b[39m\n\u001b[1;32m     38\u001b[0m T \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100_000\u001b[39m\n\u001b[0;32m---> 40\u001b[0m action_SA, \u001b[38;5;241m*\u001b[39m_ \u001b[38;5;241m=\u001b[39m \u001b[43mrecuit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_env\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mT_init\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mT_limit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlamb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mH\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m         \u001b[38;5;66;03m# res = recuit_multiple(game, T_init = T_init, T_limit = T_limit, lamb = lamb, log=log, H=T)\u001b[39;00m\n\u001b[1;32m     42\u001b[0m a \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(action_SA \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/PhD/TransportersDilemma/SA_baseline.py:36\u001b[0m, in \u001b[0;36mrecuit\u001b[0;34m(game, T_init, T_limit, lamb, var, id, log, H)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m(T\u001b[38;5;241m>\u001b[39mT_limit):\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;66;03m# infos['T'].append(T)\u001b[39;00m\n\u001b[1;32m     35\u001b[0m     sol \u001b[38;5;241m=\u001b[39m rand_neighbor(solution)\n\u001b[0;32m---> 36\u001b[0m     eval_sol, info \u001b[38;5;241m=\u001b[39m \u001b[43meval_annealing\u001b[49m\u001b[43m(\u001b[49m\u001b[43msol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgame\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;66;03m# infos['history'].append(info)\u001b[39;00m\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m m\u001b[38;5;241m%\u001b[39m\u001b[38;5;241m20\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m log:\n",
      "File \u001b[0;32m~/PhD/TransportersDilemma/SA_baseline.py:128\u001b[0m, in \u001b[0;36meval_annealing\u001b[0;34m(sol, game, malus)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21meval_annealing\u001b[39m(sol, game : AssignmentEnv, malus \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m500\u001b[39m):\n\u001b[1;32m    120\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;124;03m    This evaluates the solution of the algorithm.\u001b[39;00m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;124;03m    :param sol: the solution which is list of booleans\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;124;03m    :return: the evaluation of the solution that is an integer\u001b[39;00m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 128\u001b[0m     _, r, d, _, info \u001b[38;5;241m=\u001b[39m \u001b[43mgame\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43msol\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    129\u001b[0m     info[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdone\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m d\n\u001b[1;32m    130\u001b[0m     \u001b[38;5;66;03m# with open('log.txt', 'w+') as f:\u001b[39;00m\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;66;03m#     f.write(str(info))\u001b[39;00m\n",
      "File \u001b[0;32m~/PhD/TransportersDilemma/assignment.py:919\u001b[0m, in \u001b[0;36mAssignmentEnv.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    912\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobservation[:routes\u001b[38;5;241m.\u001b[39msize] \u001b[38;5;241m=\u001b[39m routes\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    915\u001b[0m \u001b[38;5;66;03m# if self.obs_mode == 'elimination_gain':\u001b[39;00m\n\u001b[1;32m    916\u001b[0m \u001b[38;5;66;03m#     self.observation[action == 0] = 0.\u001b[39;00m\n\u001b[1;32m    917\u001b[0m     \n\u001b[1;32m    918\u001b[0m \u001b[38;5;66;03m# print(self.observation.shape)\u001b[39;00m\n\u001b[0;32m--> 919\u001b[0m costs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_game\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_costs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdistance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    920\u001b[0m emissions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_game\u001b[38;5;241m.\u001b[39m_get_emissions(distance, time)\n\u001b[1;32m    921\u001b[0m total_costs \u001b[38;5;241m=\u001b[39m     np\u001b[38;5;241m.\u001b[39msum(costs)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "instance = 20\n",
    "env = RemoveActionEnv(game = g, saved_routes = routes, saved_dests=dests, \n",
    "                      obs_mode='elimination_gain', \n",
    "                      action_mode = 'destinations',\n",
    "                        change_instance = True, rewards_mode='normalized_terminal', instance_id = instance)\n",
    "for i in range(instance, 1000):\n",
    "    *_, info = env.reset()\n",
    "    aDP, rDP, infoDP = DP(deepcopy(env), info['excess_emission'])\n",
    "    aSA, rSA, infoSA = SA(deepcopy(env))\n",
    "    \n",
    "    if rSA>rDP:\n",
    "        print(50*'+')\n",
    "        print(i)\n",
    "        print('instance info :')\n",
    "        print(info)\n",
    "        print('routes : \\n', infoDP['rtes'])\n",
    "        print(10*'-')\n",
    "        print('la solution DP : ', aDP +1)\n",
    "        print('reward DP : ', rDP)\n",
    "        print('info DP : ', infoDP)\n",
    "\n",
    "        print('la solution SA : ', aSA +1)\n",
    "        print('reward SA : ', rSA)\n",
    "        print('info DP : ', infoSA)\n",
    "        \n",
    "        print(50*'+')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
