{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.5.2 (SDL 2.28.3, Python 3.10.11)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from stable_baselines3.common.results_plotter import load_results, ts2xy\n",
    "from stable_baselines3.common import results_plotter\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "\n",
    "import sys\n",
    "# direc = os.path.dirname(__file__)\n",
    "# pri&\n",
    "# caution: path[0] is reserved for script path (or '' in REPL)\n",
    "# print(str(path)+'/ppo')\n",
    "sys.path.insert(1, '/Users/faridounet/PhD/TransportersDilemma')\n",
    "from a_star import A_Star\n",
    "from SA_baseline import recuit\n",
    "from greedy_baseline import baseline\n",
    "from assignment import RemoveActionEnv, AssignmentEnv, GameEnv\n",
    "import pickle\n",
    "from shortcut import multi_types\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import collections\n",
    "\n",
    "from shortcut import multi_types\n",
    "from GameLearning import LRI, GameLearning, EXP3\n",
    "from SA_baseline import recuit\n",
    "from a_star import A_Star\n",
    "from greedy_baseline import baseline, greedy\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DP(env : RemoveActionEnv, excess, log = False):\n",
    "    \n",
    "    rtes = np.array([\n",
    "        [\n",
    "            env._env.initial_routes[m, i] \n",
    "            for i in range(0, len(env._env.initial_routes[m]), 2)\n",
    "        ]\n",
    "        for m in range(len(env._env.initial_routes))\n",
    "    ], dtype=int)\n",
    "\n",
    "\n",
    "    # print(env._env.distance_matrix)\n",
    "    # print(CM)\n",
    "    coeff = env._env._game.emissions_KM\n",
    "    # CM = np.array([\n",
    "    #     env._env.distance_matrix*coeff[i]\n",
    "    #     for i in range(len(coeff))\n",
    "    # ]).copy()\n",
    "    a = multi_types(env._env.distance_matrix, rtes, coeff, excess)\n",
    "\n",
    "\n",
    "    _, r, *_ = env.step(a)\n",
    "    \n",
    "    if log:\n",
    "        print(env.destinations)\n",
    "        print(env._env.distance_matrix)\n",
    "    \n",
    "    return a, r\n",
    "\n",
    "def SA(env, log = False):\n",
    "    \n",
    "    if log:\n",
    "        print(env.destinations)\n",
    "        print(env._env.distance_matrix)\n",
    "    T_init = 5_000\n",
    "    T_limit = 1\n",
    "    lamb = 0.9999\n",
    "    T = 100_000\n",
    "\n",
    "    action_SA, *_ = recuit(deepcopy(env._env), T_init, T_limit, lamb, H=T)\n",
    "            # res = recuit_multiple(game, T_init = T_init, T_limit = T_limit, lamb = lamb, log=log, H=T)\n",
    "    a = np.where(action_SA == 0)[0]\n",
    "\n",
    "    # CM = np.array([\n",
    "    #     env._env.distance_matrix*coeff[i]\n",
    "    #     for i in range(len(coeff))\n",
    "    # ]).copy()\n",
    "\n",
    "    # env = RemoveActionEnv(game = g, saved_routes = routes, saved_dests=dests, \n",
    "    #                       obs_mode='elimination_gain', \n",
    "    #                       action_mode = 'destinations',\n",
    "    #                         change_instance = True, rewards_mode='normalized_terminal', instance_id = 89)\n",
    "\n",
    "    _, r, *_, info = env.step(a)\n",
    "    \n",
    "    if log:\n",
    "        print(env.destinations)\n",
    "        print(env._env.distance_matrix)\n",
    "    \n",
    "    return a, r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 16\n",
    "with open(f'RL/game_K{K}.pkl', 'rb') as f:\n",
    "    g = pickle.load(f)\n",
    "routes = np.load(f'RL/routes_K{K}.npy')\n",
    "dests = np.load(f'RL/destinations_K{K}.npy')\n",
    "\n",
    "with open(f'res_compare_EG_A*_SA_K{K}_n100.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "    \n",
    "if K == 100:\n",
    "    g.Q = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "res_A\n",
      "9\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "res_A\n",
      "14\n",
      "[ 2  3  4  6  7  8 12 13 14 15]\n",
      "res_A\n",
      "26\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "res_A\n",
      "28\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "res_A\n",
      "32\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "res_A\n",
      "42\n",
      "[ 0  3  4  5  6  7  8 11 13 14 15]\n",
      "res_A\n",
      "43\n",
      "[ 0  1  5  6  8  9 12 13 14 15]\n",
      "res_A\n",
      "62\n",
      "[ 0  1  2  3  4  5  6  7 13 14 15]\n",
      "res_A\n",
      "68\n",
      "[ 2  3  5  6  7  9 11 12 13 14 15]\n",
      "res_A\n",
      "70\n",
      "[ 0  3  5  8  9 10 11 12 13 14 15]\n",
      "res_A\n",
      "77\n",
      "[ 0  3  4  6  7  8 11 12 13 14 15]\n",
      "res_A\n",
      "90\n",
      "[ 5  6  9 10 11 15]\n",
      "res_A\n",
      "93\n",
      "[ 0  1  2  3  6  7  8  9 10 11 12 13]\n",
      "res_A\n",
      "98\n",
      "[ 0  1  2  3  6  7  8 12 15]\n",
      "res_greedy\n",
      "9\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "res_greedy\n",
      "26\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "res_greedy\n",
      "28\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "res_greedy\n",
      "32\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "res_greedy\n",
      "68\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "res_greedy\n",
      "90\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "res_greedy\n",
      "93\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n"
     ]
    }
   ],
   "source": [
    "# On recalcule les rewards\n",
    "rewards = []\n",
    "for k in data.keys():\n",
    "    rs = np.zeros(len(data[k]))\n",
    "    for i in data[k].keys():\n",
    "        sol = data[k][i]['sol']\n",
    "        env = RemoveActionEnv(game = g, saved_routes = routes, saved_dests=dests, \n",
    "                      obs_mode='elimination_gain', \n",
    "                      action_mode = 'destinations',\n",
    "                        change_instance = True, rewards_mode='normalized_terminal', instance_id = int(i))\n",
    "        env.reset()\n",
    "        _, r, *_ = env.step(sol)\n",
    "        if r == 0:\n",
    "            print(k)\n",
    "            print(i)\n",
    "            print(sol)\n",
    "        rs[i] = r\n",
    "    rewards.append(rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# affichage\n",
    "rr = []\n",
    "for rs in rewards:\n",
    "    rr.append(rs/(rewards[0]))\n",
    "    \n",
    "plt.boxplot(\n",
    "        rr,\n",
    "        patch_artist=True,\n",
    "        )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([ 3, 12, 20, 25, 29, 30, 31, 44, 46, 47, 50, 63, 66, 79, 81, 98]),)\n",
      "(array([12, 25, 30, 63, 66, 81]),)\n",
      "(array([12, 25, 30, 63, 66, 81]),)\n"
     ]
    }
   ],
   "source": [
    "# On regarde ou la DP sous-performe\n",
    "print(np.where(rr[1]>1))\n",
    "print(np.where(rr[2]>1))\n",
    "print(np.where(rr[3]>1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On cible une instance\n",
    "instance = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max ommited: [8 8]\n",
      "solution de taille 9 [1 8] valeur 68.0\n",
      "la solution calculee à nouveau :  [ 3  8  2  1  5  6 10 16 15]\n",
      "reward obtenue par la solution calculee à nouveau :  0.396455223880597\n",
      "la solution calculee dans la sim :  [ 3  8  2  1  5  6 10 16 15]\n",
      "reward obtenue par la solution calculee dans la sim :  0.396455223880597\n"
     ]
    }
   ],
   "source": [
    "# On reessaye la DP\n",
    "env = RemoveActionEnv(game = g, saved_routes = routes, saved_dests=dests, \n",
    "                      obs_mode='elimination_gain', \n",
    "                      action_mode = 'destinations',\n",
    "                        change_instance = False, rewards_mode='normalized_terminal', instance_id = instance)\n",
    "_, info = env.reset()\n",
    "excess = info['excess_emission']\n",
    "\n",
    "rtes = np.array([\n",
    "    [\n",
    "        env._env.initial_routes[m, i] \n",
    "        for i in range(0, len(env._env.initial_routes[m]), 2)\n",
    "    ]\n",
    "    for m in range(len(env._env.initial_routes))\n",
    "], dtype=int)\n",
    "\n",
    "\n",
    "# print(env._env.distance_matrix)\n",
    "# print(CM)\n",
    "coeff = env._env._game.emissions_KM\n",
    "# CM = np.array([\n",
    "#     env._env.distance_matrix*coeff[i]\n",
    "#     for i in range(len(coeff))\n",
    "# ]).copy()\n",
    "a = multi_types(env._env.distance_matrix, rtes, coeff, excess)\n",
    "\n",
    "\n",
    "_, r, *_ = env.step(a)\n",
    "print('la solution calculee à nouveau : ', a +1)\n",
    "print('reward obtenue par la solution calculee à nouveau : ', r)\n",
    "\n",
    "print('la solution calculee dans la sim : ', data['res_DP'][instance]['sol'] + 1)\n",
    "print('reward obtenue par la solution calculee dans la sim : ', rewards[0][instance])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0 13  7  4  3  9 11 14 12  0]\n",
      " [ 0  8  2  1  5  6 10 16 15  0]]\n"
     ]
    }
   ],
   "source": [
    "print(rtes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "la solution calculee à nouveau :  [ 1  2  5  6  8 10 15 16]\n",
      "reward obtenue par la solution calculee à nouveau :  0.4533582089552239\n",
      "la solution calculee dans la sim :  [ 1  2  5  6  8 10 15 16]\n",
      "reward obtenue par la solution calculee dans la sim :  0.4533582089552239\n"
     ]
    }
   ],
   "source": [
    "env = RemoveActionEnv(game = g, saved_routes = routes, saved_dests=dests, \n",
    "                    obs_mode='elimination_gain', \n",
    "                    action_mode = 'destinations',\n",
    "                    change_instance = False, rewards_mode='normalized_terminal', instance_id = instance\n",
    ")\n",
    "_, info = env.reset()\n",
    "excess = info['excess_emission']\n",
    "T_init = 5_000\n",
    "T_limit = 1\n",
    "lamb = 0.9999\n",
    "T = 100_000\n",
    "\n",
    "action_SA, *_ = recuit(deepcopy(env._env), T_init, T_limit, lamb, H=T)\n",
    "        # res = recuit_multiple(game, T_init = T_init, T_limit = T_limit, lamb = lamb, log=log, H=T)\n",
    "a = np.where(action_SA == 0)[0]\n",
    "\n",
    "# CM = np.array([\n",
    "#     env._env.distance_matrix*coeff[i]\n",
    "#     for i in range(len(coeff))\n",
    "# ]).copy()\n",
    "\n",
    "# env = RemoveActionEnv(game = g, saved_routes = routes, saved_dests=dests, \n",
    "#                       obs_mode='elimination_gain', \n",
    "#                       action_mode = 'destinations',\n",
    "#                         change_instance = True, rewards_mode='normalized_terminal', instance_id = 89)\n",
    "\n",
    "env.reset()\n",
    "_, r, *_, info = env.step(a)\n",
    "print('la solution calculee à nouveau : ', a + 1)\n",
    "print('reward obtenue par la solution calculee à nouveau : ', r)\n",
    "\n",
    "print('la solution calculee dans la sim : ', data['res_SA'][instance]['sol'] +1)\n",
    "print('reward obtenue par la solution calculee dans la sim : ', rewards[1][instance])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.0000e+00, 9.0090e+03, 2.0000e+00, 9.0090e+03, 0.0000e+00,\n",
       "        0.0000e+00, 5.1017e+04, 1.0000e+00, 5.1017e+04, 0.0000e+00,\n",
       "        1.0000e+00, 1.0000e+00, 5.0000e+00, 1.0000e+00, 1.0000e+00]),\n",
       " {'solution_found': True,\n",
       "  'costs': 52.0,\n",
       "  'time_per_vehicle': array([0.45, 0.85]),\n",
       "  'distance_per_vehicle': array([18., 34.]),\n",
       "  'excess_emission': 5.0,\n",
       "  'omitted': 0,\n",
       "  'solution': [[0, 2, 0], [0, 1, 0]]})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from assignment import AssignmentGame\n",
    "\n",
    "\n",
    "g = AssignmentGame(\n",
    "            grid_size=12,\n",
    "            max_capacity=1,\n",
    "            Q = 7,\n",
    "            K=2,\n",
    "            emissions_KM = [.1, .3],\n",
    "            costs_KM = [1, 1],\n",
    "            seed=42\n",
    "        )\n",
    "env = RemoveActionEnv(game = g)\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max ommited: [1 1]\n",
      "solution de taille 1 [0 1] valeur 14.0\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "0\n",
      "instance info :\n",
      "{'solution_found': True, 'costs': 52.0, 'time_per_vehicle': array([0.85, 0.45]), 'distance_per_vehicle': array([34., 18.]), 'excess_emission': 1.8000000000000007, 'omitted': 0, 'solution': [[0, 1, 0], [0, 2, 0]]}\n",
      "----------\n",
      "la solution DP :  [2]\n",
      "reward DP :  0.2246376811594203\n",
      "la solution SA :  [1]\n",
      "reward SA :  0.39855072463768115\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "max ommited: [1 1]\n",
      "solution de taille 1 [0 1] valeur 24.0\n",
      "max ommited: [1 1]\n",
      "solution de taille 1 [0 1] valeur 24.0\n",
      "max ommited: [1 1]\n",
      "solution de taille 1 [0 1] valeur 36.0\n",
      "max ommited: [1 1]\n",
      "solution de taille 1 [0 1] valeur 14.0\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "4\n",
      "instance info :\n",
      "{'solution_found': True, 'costs': 52.0, 'time_per_vehicle': array([0.85, 0.45]), 'distance_per_vehicle': array([34., 18.]), 'excess_emission': 1.8000000000000007, 'omitted': 0, 'solution': [[0, 1, 0], [0, 2, 0]]}\n",
      "----------\n",
      "la solution DP :  [2]\n",
      "reward DP :  0.32608695652173914\n",
      "la solution SA :  []\n",
      "reward SA :  0.7246376811594203\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "max ommited: [1 1]\n",
      "solution de taille 1 [0 1] valeur 10.0\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "5\n",
      "instance info :\n",
      "{'solution_found': True, 'costs': 52.0, 'time_per_vehicle': array([0.85, 0.45]), 'distance_per_vehicle': array([34., 18.]), 'excess_emission': 1.8000000000000007, 'omitted': 0, 'solution': [[0, 1, 0], [0, 2, 0]]}\n",
      "----------\n",
      "la solution DP :  [2]\n",
      "reward DP :  0.2826086956521739\n",
      "la solution SA :  []\n",
      "reward SA :  0.7101449275362319\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "max ommited: [1 1]\n",
      "solution de taille 1 [0 1] valeur 14.0\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "6\n",
      "instance info :\n",
      "{'solution_found': True, 'costs': 52.0, 'time_per_vehicle': array([0.85, 0.45]), 'distance_per_vehicle': array([34., 18.]), 'excess_emission': 1.8000000000000007, 'omitted': 0, 'solution': [[0, 1, 0], [0, 2, 0]]}\n",
      "----------\n",
      "la solution DP :  [2]\n",
      "reward DP :  0.16666666666666666\n",
      "la solution SA :  [1]\n",
      "reward SA :  0.39855072463768115\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "max ommited: [1 1]\n",
      "solution de taille 1 [0 1] valeur 30.0\n",
      "max ommited: [1 1]\n",
      "max ommited: [1 1]\n",
      "solution de taille 1 [0 1] valeur 30.0\n",
      "max ommited: [1 1]\n",
      "solution de taille 1 [0 1] valeur 28.0\n",
      "max ommited: [1 1]\n",
      "solution de taille 1 [0 1] valeur 30.0\n",
      "max ommited: [1 1]\n",
      "solution de taille 1 [0 1] valeur 20.0\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "12\n",
      "instance info :\n",
      "{'solution_found': True, 'costs': 52.0, 'time_per_vehicle': array([0.45, 0.85]), 'distance_per_vehicle': array([18., 34.]), 'excess_emission': 5.0, 'omitted': 0, 'solution': [[0, 2, 0], [0, 1, 0]]}\n",
      "----------\n",
      "la solution DP :  [1]\n",
      "reward DP :  0.34057971014492755\n",
      "la solution SA :  [2]\n",
      "reward SA :  0.35507246376811596\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "max ommited: [1 1]\n",
      "solution de taille 1 [0 1] valeur 24.0\n",
      "max ommited: [1 1]\n",
      "solution de taille 1 [0 1] valeur 26.0\n",
      "max ommited: [1 1]\n",
      "solution de taille 1 [0 1] valeur 24.0\n",
      "max ommited: [1 1]\n",
      "solution de taille 1 [0 1] valeur 30.0\n",
      "max ommited: [1 1]\n",
      "solution de taille 1 [0 1] valeur 18.0\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "17\n",
      "instance info :\n",
      "{'solution_found': True, 'costs': 52.0, 'time_per_vehicle': array([0.45, 0.85]), 'distance_per_vehicle': array([18., 34.]), 'excess_emission': 5.0, 'omitted': 0, 'solution': [[0, 2, 0], [0, 1, 0]]}\n",
      "----------\n",
      "la solution DP :  [1]\n",
      "reward DP :  0.26811594202898553\n",
      "la solution SA :  [2]\n",
      "reward SA :  0.3695652173913043\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "max ommited: [1 1]\n",
      "solution de taille 1 [0 1] valeur 20.0\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "18\n",
      "instance info :\n",
      "{'solution_found': True, 'costs': 52.0, 'time_per_vehicle': array([0.85, 0.45]), 'distance_per_vehicle': array([34., 18.]), 'excess_emission': 1.8000000000000007, 'omitted': 0, 'solution': [[0, 1, 0], [0, 2, 0]]}\n",
      "----------\n",
      "la solution DP :  [2]\n",
      "reward DP :  0.2826086956521739\n",
      "la solution SA :  [1]\n",
      "reward SA :  0.35507246376811596\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "max ommited: [1 1]\n",
      "solution de taille 1 [0 1] valeur 30.0\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    *_, info = env.reset()\n",
    "    aDP, rDP = DP(deepcopy(env), info['excess_emission'])\n",
    "    aSA, rSA = SA(deepcopy(env))\n",
    "    if rSA>rDP:\n",
    "        print(50*'+')\n",
    "        print(i)\n",
    "        print('instance info :')\n",
    "        print(info)\n",
    "        print(10*'-')\n",
    "        print('la solution DP : ', aDP +1)\n",
    "        print('reward DP : ', rDP)\n",
    "\n",
    "        print('la solution SA : ', aSA +1)\n",
    "        print('reward SA : ', rSA)\n",
    "        \n",
    "        print(50*'+')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
